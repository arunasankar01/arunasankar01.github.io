---
layout: default
---
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

</head>
<body>

<h2>Introduction / Background</h2>
<p>AI models have become prominent in recent developments but are often regarded as black-box systems, making it challenging to understand their decision-making processes [1]. This has led to a growing emphasis on interpretability, especially in high-stakes fields such as healthcare. Recent advancements in explainable AI (XAI), including Concept Bottleneck Models (CBMs) [2, 3], have sought to create associations between human-understandable concepts and model outputs, enhancing interpretability. This project aims to develop interpretable AI models that provide insights into the underlying factors influencing disease detection using the HAM10000 dataset [5]. The latter is vital for dermatological research, showcasing deep learning's effectiveness in skin cancer classification and the need for interpretability in clinical settings.</p>

<h2>Dataset Description</h2>
<p>This project utilizes a medical imaging dataset: <a href="https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000" target="_blank">HAM10000</a>. The HAM10000 dataset consists of 10,015 dermatoscopic images, each labeled with one of seven skin lesion conditions. These images will aid in developing an interpretable AI model that generates concepts based on visual features to explain skin condition predictions. We will enhance interpretability by generating concepts related to lung opacity using a language model like GPT.</p>
<!-- and <a href="https://nihcc.app.box.com/v/ChestXray-NIHCC" target="_blank">ChestX-ray8</a> 
    The ChestX-ray8 dataset includes 108,948 frontal X-ray images annotated with 12 thoracic disease labels. A subset of 10,000 images will be used for training, with plans for future scaling.-->
<h2>Problem Definition</h2>
<p>Deep neural networks face two critical challenges in real-world applications: the inability to learn continuously without forgetting past knowledge and the lack of interpretability in their decision-making processes. While there has been progress in continual learning and model interpretability, the intersection of these areas remains underexplored. Our goal is to develop models that learn new information over time while retaining past knowledge and providing human-understandable, text-based explanations. This will lead to adaptable and transparent models, which are essential in healthcare and autonomous systems where trust and safety are paramount.</p>

<h2>Motivation</h2>
<p>The black-box nature of neural network models motivates this project. As AI systems in healthcare and autonomous fields become more prevalent, understanding these models is crucial. Trust in AI relies on clear explanations for decisions, especially in medicine, where professionals depend on AI for accurate diagnoses. Additionally, AI models must adapt over time to enhance reliability. Our ultimate goal is to develop AI systems that foster meaningful insights and collaboration between machines and humans in critical settings.</p>

<h2>Methods</h2>
<h3>Data Preprocessing</h3>
<p>The data preprocessing involved the following steps:</p>
<ul>
    <li><strong>Data Collection:</strong> The HAM-10000 dataset was downloaded and organized into seven separate folders, each representing a specific class based on the image-to-class mapping provided in the CSV file.</li>
    <li><strong>Initial Data Analysis:</strong> An analysis of the dataset showed it was imbalanced, with the following label distribution:</li>
</ul>

<table>
    <thead>
        <tr>
            <th>Class Label</th>
            <th>akiec</th>
            <th>bcc</th>
            <th>bkl</th>
            <th>df</th>
            <th>mel</th>
            <th>nv</th>
            <th>vasc</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Initial Count</td>
            <td>327</td>
            <td>514</td>
            <td>1099</td>
            <td>115</td>
            <td>1113</td>
            <td>6705</td>
            <td>142</td>
        </tr>
    </tbody>
</table>


<ul>
    <li><strong>Data Augmentation:</strong> To address the class imbalance, augmentation techniques such as cropping, rotation, and vertical flipping were applied. This process ensured that each class contained 500 images, resulting in a total of 3,500 images. Due to compute limitations, the model was run on this set of 3,500 images.</li>
    <li><strong>Data Splitting:</strong> The augmented dataset was divided into training, validation, and test sets using a 70/20/10 split and stored in .p files.</li>
    <li><strong>Concept Generation:</strong> For concept generation, 25 images from each class were processed through the GPT-4.0 model, producing 50 distinct concepts per class. These concepts were stored in a JSON file and split into 35 for training and 15 for testing.</li>
</ul>
<h3>ML Algorithms/Models Implemented</h3>

    <h3>Unsupervised Learning</h3>
    
    <h4>K-Means Clustering</h4>
    <p>The K-Means algorithm is applied with multiple values of <code>n_clusters</code>, starting from 2, 4, 6, and 7. For each value of <code>K</code>, the algorithm attempts to classify the data into that number of clusters, which may correspond to different skin cancer types. After fitting the model for each <code>K</code>, cluster assignments for each image are stored. This process can be viewed as an attempt to simulate continual learning in clustering, where the model adapts and evolves by increasing the number of clusters progressively. The average precision scores for each <code>K</code> value are calculated to assess the purity of clusters at each step, providing insight into how the clustering evolves with each increase in <code>K</code>.</p>
    
    <h3>Supervised Learning</h3>

    <h4>Concept Bottleneck Model (CBM)</h4>
    
    <p>The Concept Bottleneck Model (CBM) introduces interpretability into image classification by utilizing human-specified concepts as intermediaries in the prediction process. The model follows a structured pipeline:</p>
    <ol>
        <li><strong>Feature Extraction:</strong> CBM employs traditional feature encoders such as resnets as the backbone to extract meaningful visual features from images. These features are aligned to an intermediate output which represent human-interpretable concepts.</li>
        <li><strong>Concept Prediction:</strong> A linear layer is used to transform the extracted features into probabilities for each concept, enabling the model to reason through these interpretable concepts.</li>
        <li><strong>Classification:</strong> The final class prediction is made using the probabilities of the predicted concepts. This two-step process ensures that the model's decisions are explicitly tied to the intermediate concepts.</li>
    </ol>
    <p>CBM’s training involves two stages:</p>
    <ol>
        <li>The first stage focuses on aligning the image features with human-defined concepts using a loss function designed to maximize concept accuracy.</li>
        <li>The second stage optimizes class prediction accuracy based on these intermediate concepts, ensuring robust performance.</li>
    </ol>
    <p>During training, we do a joint training of the feature extractors and the concept layer. This approach ensures the model learns a good mapping of features and concepts while learning to map concepts effectively to the target classes.</p>
<!--     <p>By incorporating an explicit concept layer, CBM not only achieves competitive classification accuracy compared to end-to-end models but also facilitates transparency in the decision-making process. This is achieved through its ability to expose intermediate concept probabilities and support test-time interventions, making it a valuable tool for tasks requiring interpretability.</p> -->

    <h4>Concept-Guided Visual Classifier (CGVC)</h4>
    <p>The Concept-Guided Visual Classifier (CGVC) model employs large language models to autonomously generate interpretable concepts for image classification, eliminating the need for manual annotations. The pipeline of CGVC comprises several crucial components:</p>
    <ol>
        <li><strong>Concept Generation:</strong> As part of the data preprocessing, we utilize ChatGPT-4.0 to automatically generate a pool of candidate concepts for each image class.</li>
        <li><strong>Concept Selection:</strong> From the generated candidate pool, we select a subset of concepts for each class using a submodular optimization approach. The objective function balances two essential criteria:
            <ul>
                <li><strong>Discriminability:</strong> We compute a discriminability score for each concept based on its alignment with the images of different classes. Concepts that exhibit strong alignment with a specific class, while differing from others, are prioritized.</li>
                <li><strong>Coverage:</strong> We apply a facility location function to ensure that the selected concepts cover a broad range of unique aspects within each class.</li>
            </ul>
        </li>
        <li><strong>Concept Bottleneck Construction:</strong> We employ CLIP (Contrastive Language-Image Pre-training) to embed both the selected textual concepts and the images into a shared feature space. The concept bottleneck layer computes similarity scores between each image and the corresponding selected concepts.</li>
        <li><strong>Classification:</strong> A linear layer is used to map the concept similarity scores to final class predictions. The weights for this layer are initialized based on the concepts selected for each class, providing a strong prior to the classification process.</li>
        <li><strong>Training:</strong> The model is trained using 3500 images (500 per class) with cross-entropy loss, while the CLIP encoders remain frozen during the training process. The linear classification layer is fine-tuned to optimize the model's accuracy.</li>
    </ol>
   
    
<h2>Results and Discussion</h2>
    
<h3>Quantitative Metrics</h3>
<ul>
    <li><strong>Final Average Accuracy (FAA):</strong> Measures overall classification accuracy after all tasks.</li>
    <li><strong>Average Forgetting (AF):</strong> Indicates how much the model forgets earlier tasks when learning new ones.</li>
</ul>

<h4>K-Means Clustering Results with Forgetting</h4>
    <table>
        <tr>
            <th>K (Number of Clusters)</th>
            <th>Final Average Accuracy</th>
            <th>Average Forgetting</th>
        </tr>
        <tr>
            <td>2</td>
            <td>0.6691</td>
            <td>-</td>
        </tr>
        <tr>
            <td>4</td>
            <td>0.6450</td>
            <td>0.0241</td>
        </tr>
        <tr>
            <td>6</td>
            <td>0.6448</td>
            <td>0.0002</td>
        </tr>
        <tr>
            <td>7</td>
            <td>0.6283</td>
            <td>0.0165</td>
        </tr>
    </table>

<h4>CBM</h4> <table> <thead> <tr> <th>Experiment</th> <th>Final Average Accuracy (FAA)</th> <th>Average Forgetting</th> </tr> </thead> <tbody> <tr> <td>Exp 1</td> <td>0.50230102380</td> <td>-</td> </tr> <tr> <td>Exp 2</td> <td>0.41340288900</td> <td>0.75411123850</td> </tr> <tr> <td>Exp 3</td> <td>0.36200123345</td> <td>0.82013572833</td> </tr> <tr> <td>Exp 4</td> <td>0.30766666667</td> <td>0.81890458075</td> </tr> </tbody> </table>

<h4>CGVC</h4>
    <table>
    <thead>
        <tr>
            <th>Experiment</th>
            <th>Final Average Accuracy (FAA)</th>
            <th>Average Forgetting</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Exp 1</td>
            <td>0.74000000954</td>
            <td>0</td>
        </tr>
        <tr>
            <td>Exp 2</td>
            <td>0.54500001669</td>
            <td>0.19499999285</td>
        </tr>
        <tr>
            <td>Exp 3</td>
            <td>0.43999999762</td>
            <td>0.16500001907</td>
        </tr>
        <tr>
            <td>Exp 4</td>
            <td>0.42381848818</td>
            <td>0.20618150944</td>
        </tr>
    </tbody>
</table>

<h3>Visualizations</h3>
<h4>K-Means Clustering</h4>
<!--     <img src="k=2.png" alt="k-2.png">
    <img src="k=4.png" alt="k-2.png">
    <img src="k=6.png" alt="k-2.png"> -->
    <img src="k=7.png" alt="k-2.png">

<h4>Comparison of all 3 models:</h4>
    <img src="Final-Comparison-of-forgetting.jpg" alt="Final-Comparison-of-forgetting.jpg">
    <img src="Final-Comparison-of-FAA.jpg" alt="Final-Comparison-of-FAA.jpg">
<h3>Results Analysis</h3>
<h4>K-Means Clustering</h4>
  <p>The K-Means clustering algorithm was evaluated with different values of <strong>k</strong> (number of clusters), and the visualizations using t-SNE provide insights into the clustering performance:</p>

  <ul>
    <li><strong>K = 2</strong>: The data is divided into two large clusters, showing a clear separation. However, the average clustering precision is <strong>0.6691</strong>, suggesting that this configuration may be too simplistic.</li>
    <li><strong>K = 4</strong>: With four clusters, the t-SNE visualization reveals more structure in the data, but the average clustering precision drops slightly to <strong>0.6450</strong> with a forgetting rate of <strong>0.0241</strong>.</li>
    <li><strong>K = 6</strong>: This configuration shows a more complex segmentation, with six distinct clusters. The average clustering precision is <strong>0.6448</strong>, and the forgetting rate is minimal at <strong>0.0002</strong>, indicating that this value balances precision and granularity well.</li>
    <li><strong>K = 7</strong>: Increasing to seven clusters results in some overlap between clusters, with an average precision of <strong>0.6283</strong> and a forgetting rate of <strong>0.0165</strong>, suggesting diminishing returns beyond k = 6.</li>
  </ul>

  <p>Overall, <strong>k = 6</strong> provides the most balanced clustering performance with minimal overlap and high precision.</p>
  <p>The results for K-means are higher than our model since we treat the image features as vectors upon which we perform the clustering; this method may be post-hoc interpretable but lacks a clear understanding of fine-grained features of the image. This is tackled in our method CGVC which helps us to correlate the features to an understandable human term (aka concept). Another reason why the results are higher than supervised methods is because we let the model run till convergence which takes a long time to train. Furthermore, the results do not reflect the ability of the model to discover emergent behaviour which would be possible only by using large transformer-based models which can serve crucial for learning cross-class relationships (learn to map old concepts to new classes and new classes with old concepts).</p>

<h4>CBM</h4>
    <p>In these experiments, we evaluated the performance of the Concept Bottleneck Model (CBM) across four trials, varying the number of concepts used while keeping the exemplar size fixed at 100. The two primary metrics analyzed were the final average accuracy (<em>mAP</em>) and forgetting, which measures the model's ability to retain knowledge from previous tasks as new ones are learned.</p>
<!--     <h6>mAP Results:</h4> -->
    <p>mAP Results: The CBM model showed a decreasing trend in accuracy across experiments. It started with a high mAP of <strong>0.50</strong> in Experiment 1, but the accuracy dropped in subsequent experiments. By Experiment 4, the mAP had decreased to <strong>0.30</strong>. This suggests that while the model performs well in early stages, its accuracy declines as more concepts are added and the model faces additional tasks.</p>
<!--     <h4>Forgetting Results:</h4> -->
    <p>Forgetting Results: The model's forgetting rate was initially <strong>0</strong> in Experiment 1, indicating no forgetting when learning the first task. However, in Experiments 2 and 3, forgetting increased significantly, reaching values of <strong>0.75</strong> and <strong>0.82</strong>, respectively. This shows that CBM struggles with forgetting as more tasks are introduced, and it is more prone to losing information from earlier tasks. </p>


<h4>CGVC</h4>
    <p>In these experiments, we evaluated a continual learning model's performance across four trials, each varying in the number of concepts used while maintaining an exemplar size of 100 to equally partition past class samples. The primary metric analyzed was the <em>final average accuracy</em>, denoted by the first term, and <em>forgetting</em>, represented by <code>cgvc_forgetting</code>.</p>
<p>The reason for observing high forgetting in our method stems from the size of exemplar that we use. Here we only use 50 samples for the buffer memory which makes it a bit hard to overcome forgetting. In case of k-means we use all the datapoints for each experience which makes it favorable for gaining high accuracy and in turn low forgetting. We will be experimenting our model with increased buffer size to overcome this gap in the next iteration.</p>

 <p>Overall, the CGVC model not only offers high prediction accuracy comparable to end-to-end methods but also enhances interpretability by exposing intermediate concept scores and the learned concept-class associations. This transparency provides valuable insight into the model’s decision-making process, ensuring that its predictions are both explainable and reliable.</p>
    
    
<h2>Project Goals</h2>
<ul>
    <li><strong>Develop Continuous Learning:</strong> Create a neural network model capable of learning new information without forgetting previously acquired knowledge.</li>
    <li><strong>Enhance Interpretability:</strong> Provide clear, human-understandable insights into decision-making processes.</li>
</ul>

  <h2>Next Steps</h2>
  <ul>
<!--     <li>Construct a Concept Bottleneck Model (CBM) utilizing linear layers over the course of the coming week.</li>
    <li>Conduct a comparative analysis between the three models.</li>
    <li>Perform hyper-parameter tuning to enhance the performance of the CGVC model.</li> -->
    <li>Experiment with strategies for exemplary replacements.</li>
    <li>We will try to run our models on ChestX-ray8 dataset and perform a comparison study.</li>
<!--     <li>Upon completing these tasks, we will finish our final project report.</li> -->
  </ul>

<h2>Expected Results</h2>
<p>We anticipate high diagnostic accuracy for the AI models developed from the HAM10000 dataset, measured by FAA. Models should exhibit low AF, demonstrating their ability to learn new information while retaining past knowledge. Enhanced interpretability will be assessed through the ACR metric, indicating effective concept utilization. Ultimately, we expect our model to adapt over time, improving performance in healthcare applications.</p>

<h2>Gantt Chart</h2>
<img src="gnatt-for-final.png" alt="Gantt Chart">

<h2>Contribution Table</h2>
<table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Proposal Contributions</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Ajay Bhat</td>
        <td>K-Means: Model Selection, Data Preprocessing, Model Coding; Model Comparison and Presentation</td>
      </tr>
      <tr>
        <td>Aruneswari Sankar</td>
        <td>K-Means: Data Sourcing and Cleaning, Model Coding, Results Evaluation and analysis; Model Comparison and Report</td>
      </tr>
      <tr>
        <td>Saikrishnan Sankar</td>
        <td>CGVC: Data Sourcing and Cleaning, Model Selection, Model Coding, Results Evaluation and analysis; Model Comparison, Presentation</td>
      </tr>
      <tr>
        <td>Sri Siddarth Chakaravarthy P</td>
        <td>CGVC and CBM: Data Sourcing and Cleaning, Model Coding, Results Evaluation and analysis; Model Comparison and Recording</td>
      </tr>
      <tr>
        <td>Vimalan Krishnan Manivannan</td>
        <td>CGVC and CBM: Data Preprocessing, Results Evaluation and analysis; K-Means: Data Sourcing and Cleaning; Model Comparison and Report</td>
      </tr>
    </tbody>
  </table>

<h2>Proposal Video & Presentation Slides</h2>
<p><a href="https://youtu.be/BnxMtnb5css" target="_blank">Proposal Video</a></p>
<p><a href="https://docs.google.com/presentation/d/1gqot6oGNl0aXS3QraKKgu5Ru6e4wC4C3BTgFA2KYU7E/edit?usp=sharing" target="_blank">Slides</a></p>

<h2>References</h2>
<ol>
    <li>Rudin, C. (2019). <em>Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead.</em> Nature Machine Intelligence, 1(5), 206-215.</li>
    <li>Koh, P. W., et al. (2020). <em>Concept bottleneck models.</em> In International conference on machine learning (pp. 5338-5348). PMLR.</li>
    <li>Yang, Y., et al. (2023). <em>Language in a bottle: Language model guided concept bottlenecks for interpretable image classification.</em> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 19187-19197).</li>
    <li>Wang X, Peng Y, Lu L, et al. (2017). <em>ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.</em> CVPR 2017. <a href="https://nihcc.app.box.com/v/ChestXray-NIHCC">https://nihcc.app.box.com/v/ChestXray-NIHCC</a></li>
    <li>Esteva A, Kuprel B, et al. (2017). <em>Dermatologist-level classification of skin cancer with deep neural networks.</em> Nature, 542(7639), 115-118. <a href="https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000">https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000</a></li>
</ol>




</body>
</html>
